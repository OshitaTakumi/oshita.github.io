<!DOCTYPE html>
<html lang="ja">
<head>
<meta charset="UTF-8">

<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
	MathJax.Hub.Config({
	  tex2jax: {
		inlineMath: [['$','$']]
	  }
	});
</script>

<title>Contrast to Divide: Self-Supervised Pre-Training for Learning with Noisy Labels	要約</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="description" content="Contrast to Divide: Self-Supervised Pre-Training for Learning with Noisy Labels
要約">
<link rel="stylesheet" href="../../../css/style.css">
</head>

<body>

<div id="container">

<header>

<div id="logo">
<h1><a href="index.html"><img src="images/logo.png" alt="Learning with Noisy labels via Self-supervised Adversarial Noisy Masking
	"></a></h1>
</div>

</header>

<!--開閉ブロック-->
<div id="menubar">

<nav>
	<ul>
	<li><a href="index.html">ホーム</a></li>
	<li><a href="selh-intro.html">自己紹介</a></li>
	<li><a href="">過去の研究</a>
		<ul>
			<li><a href="b3.html">個人製作アプリ</a></li>
			<li><a href="b3.html">学部３年</a></li>
			<li><a href="b4.html">学部４年</a></li>
			<li><a href="404.html">修士１年</a></li>
			<li><a href="404.html">修士２年</a></li>
		</ul>
	</li>
	<li><a href="club.html">学外活動</a></li>
	<li><a href="contact.html">お問い合わせ</a></li>
	</ul>
</nav>

<!-- <div class="sh">
<p>※800px以下のメニュー開閉時にのみ表示させたい情報があればここ（shボックスの中）に入れて下さい。<br>
サンプルテキスト。サンプルテキスト。<br>
サンプルテキスト。サンプルテキスト。<br>
サンプルテキスト。サンプルテキスト。</p>
</div> -->
<!--/.sh-->

</div>
<!--/#menubar-->

<main>

<section>

<h2>論文</h2>
<p>・ Year ： ICLR 2021<br>
	・ <a href="https://arxiv.org/pdf/2103.13646">リンク</a><br> 
	・ <a href="https://github.com/ContrastToDivide/C2D">github</a>
</p>

<h2>１．どんなものか</h2>
<p>
	noiseラベルを含むデータを用いた学習のうちwarm upに着目．通常はwarm up段階ではラベルあり学習を行いう．
	ノイズを含むデータセットを用いる場合，この学習が後の学習に大きく影響を与え，ノイズデータセットではモデルが
	ノイズデータに過適合してしまう．この問題を自己教師あり学習したモデルを学習済みモデルとして使用することで解決．
	特に，ノイズ率の高いデータにおいて他の手法と比較し，性能向上が見られた．<br>
	<img src="./cifar10.png"><br>
	また，論文内では自己教師あり学習，半教師あり学習
	によるLNL性能についても言及している．
</p>

<h2>２．先行研究との差分</h2>
<p>
	モデルの学習初期におけるノイズラベルデータへの過適合の決定的要因は未だ判明していない．そのため既存研究では経験則的なcnnの振る舞いを利用している．
	既存の手法はwarm up時に強い正則化を用いることでノイズデータに対する過適合を防ぐが，これと異なり提案手法では正則などに用いるハイパーパラメータ
	が不要である．<br>
	また，異なるノイズ率を持つデータセットに対しても一貫した性能を持ち，半教師ありベースの手法など他のLNL手法と容易に組み合わせることが可能である．
	事前学習なし，Imagenetによる事前学習ありの場合と比較してClothing1Mのcleanデータに対するノイズの識別率は以下の通り．<br>
	<img  src="./noise_detect.png">
</p>

<h2>３．技術や研究のキモ</h2>
<p>
	warm upの段階を自己教師あり学習に置き換えることで，今までは深層学習の学習初期はノイズデータに汎化しにくいという経験則的な現象に従っていた
	点について解消した．
</p>

<h2>４．有効性の証明</h2>
<p>
	cifar10,cifar100,clothing1mで実験．<br>
	cifar10における実験結果<br>
	<image src="./cifar10.png"><br>
	cifar100における実験結果<br>
	<image src="./cifar100.png"><br>
	clothing1mにおける実験結果<br>
	<image src="./clothinig1m.png"><br>
	webvisionにおける実験結果<br>
	<image src="./webvision.png"><br>
</p>

<h2>５．議論</h2>	
clothing1Mに関してsimCLRによるssl事前学習モデルとImagenetで事前学習したモデル間で性能差なし．
noise率が高くなるとdevidemix系よりもmixmatchの方が性能はいい感じ．でも実世界ではあまり考えられなさそう．

</section>


</main>

<footer>


<div class="copy">
<small>Copyright&copy; <a href="index.html">SAMPLE COMPANY</a> All Rights Reserved.</small>
<span class="pr"><a href="https://template-party.com/" target="_blank">《Web Design:Template-Party》</a></span>
</div>

</footer>

<!--開閉ボタン（ハンバーガーアイコン）-->
<div id="menubar_hdr">
<span></span><span></span><span></span>
</div>

</div>
<!--/#container-->

<!--jQueryの読み込み-->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>

<!--パララックス（inview）-->
<script src="https://cdnjs.cloudflare.com/ajax/libs/protonet-jquery.inview/1.1.2/jquery.inview.min.js"></script>
<script src="js/jquery.inview_set.js"></script>

<!--このテンプレート専用のスクリプト-->
<script src="js/main.js"></script>

<!--ページの上部へ戻るボタン-->
<div class="pagetop"><a href="#"><i class="fas fa-angle-double-up"></i></a></div>

</body>
</html>
