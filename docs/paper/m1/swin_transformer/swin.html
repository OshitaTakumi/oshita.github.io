<!DOCTYPE html>
<html lang="ja">
<head>
<!-- Mathjaxの設定．これで数式のインライン形式が生成可能 -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
	MathJax.Hub.Config({
	  tex2jax: {
		inlineMath: [['$','$']]
	  }
	});
</script>

<meta charset="UTF-8">
<title>Swin Transformer 要約</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="description" content="Swin Transformer: Hierarchical Vision Transformer using Shifted Windows 要約">
<link rel="stylesheet" href="../../style.css">
</head>

<body>

<div id="container">

<header>

<div id="logo">
<h1><a href="index.html"><img src="images/logo.png" alt="swin"></a></h1>
</div>

</header>

<!--開閉ブロック-->
<div id="menubar">

<nav>
	<ul>
	<li><a href="index.html">ホーム</a></li>
	<li><a href="selh-intro.html">自己紹介</a></li>
	<li><a href="">過去の研究</a>
		<ul>
			<li><a href="b3.html">個人製作アプリ</a></li>
			<li><a href="b3.html">学部３年</a></li>
			<li><a href="b4.html">学部４年</a></li>
			<li><a href="404.html">修士１年</a></li>
			<li><a href="404.html">修士２年</a></li>
		</ul>
	</li>
	<li><a href="club.html">学外活動</a></li>
	<li><a href="contact.html">お問い合わせ</a></li>
	</ul>
</nav>

<!-- <div class="sh">
<p>※800px以下のメニュー開閉時にのみ表示させたい情報があればここ（shボックスの中）に入れて下さい。<br>
サンプルテキスト。サンプルテキスト。<br>
サンプルテキスト。サンプルテキスト。<br>
サンプルテキスト。サンプルテキスト。</p>
</div> -->
<!--/.sh-->

</div>
<!--/#menubar-->

<main>

<section>

<h2>論文</h2>
<p>・ Year ： 2021<br>
	・ <a href="https://arxiv.org/abs/2103.14030">リンク</a><br> 
	・ <a href="https://github.com/microsoft/Swin-Transformer">github</a>
</p>

<h2>１．どんなものか</h2>
<p>言語から視覚へのtransformerの適応には<br>
	・視覚的実体のスケールの大きな変化<br>
	・テキスト中の単語と対応する画像の解像度との差から生じる計算の困難性<br>
	などの２つのドメインの違いから生じる問題が課題である．
	この問題に対して表現がshifted windowsで計算される階層的transformerを提案している．
</p>

<h2>２．先行研究との差分</h2>
<p>今までのtransformerはself-attensionの計算量が二次関数に従うため，高解像度画像を用いたピクセル単位のタスクにおいては
	計算量の観点から実現不可能だった．<br>
	これに対して，swin transformerは階層的特徴マップを構築することで画像サイズに対して線形な計算量で計算可能となった．<br>
	階層的とは，transfirmerの深い層では隣接するパッチを徐々にマージして行くことを示す．これにより，特徴ピラミッドネットワーク
	やU-NET等を容易に利用できる．<br>
	<image src = "./swin.png"></image>
</p>

<h2>３．技術や研究のキモ</h2>

<h3>アーキテクチャ</h3>
<p>
	層が深くなるにつれてパッチを統合していく．<br>
	swin-transformer-blockはself-attensionを適応した後の出力を示す．<br>
	ここで特徴マップのサイズはvggやresnetと同じになるように調整されている．
	これは既存のcnnがバックボーンになっている部分を置き換えられるようにとのこと．<br>
	<image src = "./arch.png"></image>
</p>

<h3>Swin-Transformer-Block</h3>
<p>
	このブロックは通常のtransformerで用いられているmultihead-self-attensionの部分が
	shifted windowモジュールに置き換えられている．<br>
	それ以外は通常のtransformerと同じ構造をしている．<br>
	詳細な構造は上の図を参照．
<h4>Shifted-window</h4>
通常のtransformerではグローバルなself-attensionを行うため，高解像度画像を用いるようなタスクでは計算が時に関数的に増加するため適応が困難であった．<br>
それに対して，shifted-windowどとにself-attensionをとることでこの問題を解決した．<br>
<img src="./order.png"><br>
一方で，特定の領域にのみattensionを用いるため，通常のものより能力が制限されてしまう．そこで，モジュールごとに前回のモジュールではattensionを見なかった領域について
attension計算を行うようにwindowを$(w,h)=(\frac{M}{2},\frac{M}{2})$分移動させる．<br>
画像に対してwindowが外れてしまう場合にはmaskを活用．この部分が今愛知まだ自分の中で分かってないので再度勉強が必要．
</p>


<h2>４．有効性の証明</h2>
imageNet-1k，COCO，ADE20Kを用いてそれぞれ画像分類，物体検出，セグメンテーションを実験．
<p>
<h3>ImageNetにおけるclassification</h3>>
transformerのベースであるDeitと比較．同程度のモデルアーキテクチャの複雑さでありながら，大幅に性能向上．<br>
また当時の最新convNetであるregnetやefficientnetに対してもわずかに性能が向上しており，シンプルなswin transformerが徹底的なアーキテクチャ研究により
開発されたconvNetの性能を向上したことはswinの可能性について示している．<br>
<div style="text-align:center;"><img src="./swim_result1.png"></div>
</p>

<p>
<h3>ICOCOにおけるobject detection</h3>>
resnet50と比較してswinはわずかにモデルサイズ、FLOP、レイテンシが大きくなるものの，性能向上が確認できた．
また，モデルサイズ，FLOP，レイテンシが同程度のresnextとの比較実験においても優位性が確認された．
Deitに対しても優位性が確認され，推論速度についても大幅に早くなっている．
<ul>
	<li><img src="./coco_result1.png"></li>
	<li><img src="./coco_result2.png"></li>
</ul>
</p>

<p>
<h3>ADE20Kを用いたSemantic Segmentation</h3>>
transformerのベースであるDeit-sとswin-sのひあっくでは同程度の計算コストにおいてmIoUで優位．<br>
resnet101，resnextとの比較実験においても同様に優位性が確認された．
</p>

<p>
<h3>shifted windowの有効性証明</h3>>
上記で載せた実験について通常の1windowの例とshifted windowで実験比較．<br>
また，相対位置バイアスをshiftに乗せた場合の実験も行った．．
<img src="./ade_result1.png">
</p>

<h2>５．議論</h2>	
<p>画像分類精度については絶対位置埋め込みにより分類性能は向上するものの，
	物体検出や，セグメンテーションにおいてはむしろ性能が下がってしまう．<br>
</p>


<h2>感想</h2>	
<p>self-attensionについては自身の理解が全く及んでいないため，Transformer，Vision 
	Transformerについて勉強しつつ理解する必要がある．<br>
</p>


</section>


</main>

<footer>


<div class="copy">
<small>Copyright&copy; <a href="index.html">SAMPLE COMPANY</a> All Rights Reserved.</small>
<span class="pr"><a href="https://template-party.com/" target="_blank">《Web Design:Template-Party》</a></span>
</div>

</footer>

<!--開閉ボタン（ハンバーガーアイコン）-->
<div id="menubar_hdr">
<span></span><span></span><span></span>
</div>

</div>
<!--/#container-->

<!--jQueryの読み込み-->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>

<!--パララックス（inview）-->
<script src="https://cdnjs.cloudflare.com/ajax/libs/protonet-jquery.inview/1.1.2/jquery.inview.min.js"></script>
<script src="js/jquery.inview_set.js"></script>

<!--このテンプレート専用のスクリプト-->
<script src="js/main.js"></script>

<!--ページの上部へ戻るボタン-->
<div class="pagetop"><a href="#"><i class="fas fa-angle-double-up"></i></a></div>

</body>
</html>
